# -*- coding: utf-8 -*-
"""Submission_Machine_Learning_Pemula_Klasifikasi_Gambar_Tiga_Kelas_Dicoding.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rE1xJd_2-PHGT9vJ3f56fftllm1dJOBb

<a href="https://colab.research.google.com/drive/1cpvw8pNBWgNyurNYEngQzwRuIc8qWzBD#scrollTo=view-in-github" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

<h1><center>INFORMASI DIRI</center></h1>


**Fahmi Ardiansyah**


> Universitas Negeri Semarang



![an image](https://img.icons8.com/material-two-tone/2x/incoming-call.png)
**081573658211**

![an image](https://img.icons8.com/fluent-systems-regular/2x/gmail.png)
**fahmiardiansyah959@gmail.com**

![an image](https://img.icons8.com/material-rounded/2x/address.png)
**Cirebon, Jawa Barat**

![an image](https://img.icons8.com/fluent-systems-filled/2x/linkedin.png)
[Linkedin](https://www.linkedin.com/in/fahmi-ardiansyah-759a73179/)

![an image](https://img.icons8.com/?size=1x&id=32323&format=png)
[Instagram](https://www.instagram.com/karepdewek_)

<h1><center>Submission at Dicoding</center></h1>

#### Klasifikasi Gambar

Membuat program jaringan saraf tiruan menggunakan TensorFlow. Program harus mampu mengenali bentuk tangan yang membentuk gunting, batu, atau kertas.
"""

# Mengimport Library yang digunakan
import tensorflow as tf
import zipfile,os,shutil
import numpy as np
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Load Dataset dari website
!wget --no-check-certificate \
        https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip \
        -O /tmp/rockpaperscissors.zip

"""Karena Dataset masih dalam bentuk ZIP, kita perlu mengekstrak datanya. Kemudian mendefinisikan suatu direktori untuk data latih dan dan validasi

"""

#ekstrak dataset
local_zip = '/tmp/rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()

# Penggunaan Callback mencegah overfitting dan menghentikan training setelah akurasi terpenuhi
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') > 0.97):
      print("\nAkurasi melewati 97%, hentikan proses training!")
      self.model.stop_training = True

callbacks = myCallback()

# split dataset kemudian membuat direktori
base_dir = '/tmp/rockpaperscissors'
train_dir = os.path.join(base_dir,'train')
validation_dir = os.path.join(base_dir, 'val')
roc_dir = os.path.join(base_dir,'rock')
pap_dir = os.path.join(base_dir, 'paper')
sci_dir = os.path.join(base_dir, 'scissors')

import os

# Definisi direktori
train_dir = '/tmp/rockpaperscissors/train'
validation_dir = '/tmp/rockpaperscissors/validation'

# Periksa apakah direktori sudah ada atau belum, kemudian buat jika belum ada
if not os.path.exists(train_dir):
    os.mkdir(train_dir)

if not os.path.exists(validation_dir):
    os.mkdir(validation_dir)

train_roc = os.path.join(train_dir, 'rock')
train_pap = os.path.join(train_dir, 'paper')
train_sci = os.path.join(train_dir, 'scissors')
val_roc = os.path.join(validation_dir, 'rock')
val_pap = os.path.join(validation_dir, 'paper')
val_sci = os.path.join(validation_dir, 'scissors')

import os

# Definisikan root directory
base_dir = '/tmp/rockpaperscissors'

# Definisikan sub-direktori untuk data training dan validasi
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'validation')

# Definisikan sub-direktori untuk setiap kategori
train_roc_dir = os.path.join(train_dir, 'rock')
train_pap_dir = os.path.join(train_dir, 'paper')
train_sci_dir = os.path.join(train_dir, 'scissors')

val_roc_dir = os.path.join(validation_dir, 'rock')
val_pap_dir = os.path.join(validation_dir, 'paper')
val_sci_dir = os.path.join(validation_dir, 'scissors')

# Periksa apakah direktori sudah ada atau belum, kemudian buat jika belum ada
if not os.path.exists(train_dir):
    os.mkdir(train_dir)
if not os.path.exists(validation_dir):
    os.mkdir(validation_dir)

if not os.path.exists(train_roc_dir):
    os.mkdir(train_roc_dir)
if not os.path.exists(train_pap_dir):
    os.mkdir(train_pap_dir)
if not os.path.exists(train_sci_dir):
    os.mkdir(train_sci_dir)

if not os.path.exists(val_roc_dir):
    os.mkdir(val_roc_dir)
if not os.path.exists(val_pap_dir):
    os.mkdir(val_pap_dir)
if not os.path.exists(val_sci_dir):
    os.mkdir(val_sci_dir)

"""Dari direktori yang ada, dibuat sub-kategori untuk menampung data training dan data validasi dengan pembagiannya 40% data validasi dari total dataset."""

# train dan test split
# memecah setiap direktori menjadi data train dan data validasi(validation 40% of dataset)
train_roc_dir, val_roc_dir = train_test_split(os.listdir(roc_dir), test_size = 0.40)
train_pap_dir, val_pap_dir = train_test_split(os.listdir(pap_dir), test_size = 0.40)
train_sci_dir, val_sci_dir = train_test_split(os.listdir(sci_dir), test_size = 0.40)

for file in train_roc_dir:
  shutil.copy(os.path.join(roc_dir, file), os.path.join(train_roc, file))
for file in train_pap_dir:
  shutil.copy(os.path.join(pap_dir,file), os.path.join(train_pap,file))
for file in train_sci_dir:
  shutil.copy(os.path.join(sci_dir,file), os.path.join(train_sci,file))
for file in val_roc_dir:
  shutil.copy(os.path.join(roc_dir, file), os.path.join(val_roc,file))
for file in val_pap_dir:
  shutil.copy(os.path.join(pap_dir,file), os.path.join(val_pap,file))
for file in val_sci_dir:
  shutil.copy(os.path.join(sci_dir,file), os.path.join(val_sci,file))

"""Untuk mempersiapkan data dan mengaugmentasi gambar dari data baru menggunakan Image Data Generator."""

train_data_augmentation = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

test_data_augmentation = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    vertical_flip=True,
    fill_mode='nearest'
)

train_generator = train_data_augmentation.flow_from_directory(
    train_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical',
    shuffle=True,  # Acak data
    subset='training'  # Hanya ambil subset training
)

validation_generator = test_data_augmentation.flow_from_directory(
    validation_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical',
    shuffle=True,  # Acak data
    subset='training'  # Hanya ambil subset training
)

# Batasi jumlah gambar sesuai dengan yang diinginkan
desired_train_samples = 1314
desired_val_samples = 874

train_generator.samples = desired_train_samples
validation_generator.samples = desired_val_samples

# Reset ulang generator agar sesuai dengan jumlah gambar baru
train_generator._set_index_array()
validation_generator._set_index_array()

"""Dari ukuran pembagian data validasi 40% dari total dataset, ditemukan: Data training memiliki 1312 sampel gambar dengan 3 class, dan Data validasi memiliki 876 sampel gambar dengan 3 class.

Setelah data kita telah siap, kita bisa membangun arsitektur sebuah CNN.
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense
import tensorflow as tf

model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),
    MaxPooling2D(2, 2),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Flatten(),
    Dropout(0.5),
    Dense(512, activation='relu'),
    Dense(3, activation='softmax')
])

model.summary()
model.compile(loss='categorical_crossentropy',
              optimizer=tf.optimizers.Adam(),
              metrics=['accuracy'])

"""Setelah membuat arsitektur dari CNN, kemudian memanggil fungsi compile pada object model, dan tentukan loss function serta optimizer.

compile model dengan optimizer = 'Adam' dan loss function = 'categorical_crossentropy'

loss function pada kasus klasifikasi 2 class dan 3 class berbeda. 2 class menggunakan 'binary crossentropy' sedangkan 3 class menggunakan 'categorical_crossentropy'.
"""

history = model.fit(
    train_generator,
    steps_per_epoch=41,  # Total train images / batch_size
    epochs=10,
    validation_data=validation_generator,
    validation_steps=27,  # Total validation images / batch_size
    verbose=2,
    callbacks=[callbacks]  # Assuming you have defined the callbacks
)

"""Meliat Grafik dari 'loss dan training loss' serta 'training accuracy dan validation accuracy'."""

# plot loss train & validation
plt.plot(history.history['loss'], 'r', label='Training Loss')
plt.plot(history.history['val_loss'], 'b', label='Validation Loss')
plt.title('Loss & Validation Loss')
plt.ylabel('Value')
plt.xlabel('Epoch')
plt.legend(loc="upper right")
plt.show()

# plot accuracy train & validation
plt.plot(history.history['accuracy'], 'r', label='Training Accuracy')
plt.plot(history.history['val_accuracy'], 'b', label='Validation Accuracy')
plt.title('Accuracy & Validation Accuracy')
plt.ylabel('Value')
plt.xlabel('Epoch')
plt.legend(loc="lower right")
plt.show()

"""Mengunggah gambar untuk diprediksi"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import files
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

uploaded = files.upload()

for fn in uploaded.keys():

  path = fn
  img = image.load_img(path, target_size =(150,150))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)

  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)

print(fn)
  if classes[0,0]!=0:
    print('Kertas')
  elif classes[0,1]!=0:
    print('Batu')
  else:
    print('Gunting')